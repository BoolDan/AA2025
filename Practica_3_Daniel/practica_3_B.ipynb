{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Parte B***: Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\danid\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\danid\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\danid\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\danid\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Preguntas***\n",
    "1. ¿Que significa que el batch_size sea 4? Explica cómo afectaría al cálculo de los pesos en cada epoch.\n",
    "La variable batch_size define cuantos datos se procesan en cada lote, al tener un valor pequeño el calculo de los pesos se realiza más veces en cada epoch.\n",
    "\n",
    "2. ¿Por qué al dividir el conjunto de entrenamiento el parámetro shuffle está a True, mientras que el conjunto de test está a False?\n",
    "El parametro shuffle reorganiza de manera aleatoria los datos que se cargan en cada epoch, esto puede ser beneficioso para evitar patrones que puedan afectar al desempeño del modelo, en el test no es necesario ya que son los datos de validación y por lo tanto no es necesario hacer el shuffle.\n",
    "\n",
    "3. Ver en la celda de código adyacente.\n",
    "\n",
    "4. Indica la línea de código donde se realiza el cálculo de los gradientes para determinar cómo modificar los pesos (los filtros kernel), e indica la línea de código donde se recalculan los pesos. ¿Qué se ha tenido que realizar antes para poder hacer el cálculo de gradientes y la actualización de pesos?\n",
    "Los gradientes se calculan usando la línea de loss.backward(), mientras que los pesos se actualizan en la la línea de optimizer.step().\n",
    "Para poder calcular los gradientes y actualizar los pesos e necesita realizar el calculo del forward pass y después se calcula la perdida (loss=criterion(outputs, label)).\n",
    "\n",
    "5. ¿Cuál es la estructura de los outputs que se obtienen en outputs = net(images)?\n",
    "La estructura de output esta definida por el batch_size y el número de clases de los datos, es decir, si el batch size es 4 y hay 10 clases en los datos entonces tendremos un output de [4, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pregunta 3\n",
    "'''\n",
    "class Net(nn.Module):  # Define una clase para la red neuronal que hereda de nn.Module\n",
    "    def __init__(self):  # Constructor de la clase\n",
    "        super().__init__()  # Llama al constructor de la clase base nn.Module\n",
    "        # Primera capa convolucional: toma imágenes con 3 canales (RGB), aplica 6 filtros de tamaño 5x5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  \n",
    "        # Capa de pooling: aplica max pooling con un tamaño de ventana 2x2 y un paso (stride) de 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        # Segunda capa convolucional: toma 6 canales de entrada y aplica 16 filtros de tamaño 5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        # Primera capa completamente conectada: conecta 16 * 5 * 5 entradas (salida de la convolución) a 120 neuronas\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  \n",
    "        # Segunda capa completamente conectada: conecta 120 neuronas a 84 neuronas\n",
    "        self.fc2 = nn.Linear(120, 84)  \n",
    "        # Tercera capa completamente conectada: conecta 84 neuronas a 10 neuronas (una por cada clase)\n",
    "        self.fc3 = nn.Linear(84, 10)  \n",
    "\n",
    "    def forward(self, x):  # Define el flujo de datos a través de la red (forward propagation)\n",
    "        # Aplica la primera capa convolucional, seguida de ReLU y max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        # Aplica la segunda capa convolucional, seguida de ReLU y max pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        # Aplana el tensor (convierte las dimensiones de características en una sola dimensión, excepto el batch)\n",
    "        x = torch.flatten(x, 1)  # Mantiene la dimensión del batch (dimensión 0)\n",
    "        # Aplica la primera capa completamente conectada con activación ReLU\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        # Aplica la segunda capa completamente conectada con activación ReLU\n",
    "        x = F.relu(self.fc2(x))  \n",
    "        # Aplica la última capa completamente conectada (sin activación, ya que es la salida final)\n",
    "        x = self.fc3(x)  \n",
    "        return x  # Devuelve la salida final (logits para las 10 clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#Declaramos las dos redes neuronales que vamos a utilizar\n",
    "class Net1(nn.Module):  # Define una clase para la red neuronal que hereda de nn.Module\n",
    "    def __init__(self):  # Constructor de la clase\n",
    "        super().__init__()  # Llama al constructor de la clase base nn.Module\n",
    "        # Primera capa convolucional: toma imágenes con 3 canales (RGB), aplica 6 filtros de tamaño 5x5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)  \n",
    "        # Capa de pooling: aplica max pooling con un tamaño de ventana 2x2 y un paso (stride) de 2\n",
    "        self.pool = nn.MaxPool2d(2, 2)  \n",
    "        # Segunda capa convolucional: toma 6 canales de entrada y aplica 16 filtros de tamaño 5x5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        # Primera capa completamente conectada: conecta 16 * 5 * 5 entradas (salida de la convolución) a 120 neuronas\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  \n",
    "        # Segunda capa completamente conectada: conecta 120 neuronas a 84 neuronas\n",
    "        self.fc2 = nn.Linear(120, 84)  \n",
    "        # Tercera capa completamente conectada: conecta 84 neuronas a 10 neuronas (una por cada clase)\n",
    "        self.fc3 = nn.Linear(84, 10)  \n",
    "\n",
    "    def forward(self, x):  # Define el flujo de datos a través de la red (forward propagation)\n",
    "        # Aplica la primera capa convolucional, seguida de ReLU y max pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        # Aplica la segunda capa convolucional, seguida de ReLU y max pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        # Aplana el tensor (convierte las dimensiones de características en una sola dimensión, excepto el batch)\n",
    "        x = torch.flatten(x, 1)  # Mantiene la dimensión del batch (dimensión 0)\n",
    "        # Aplica la primera capa completamente conectada con activación ReLU\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        # Aplica la segunda capa completamente conectada con activación ReLU\n",
    "        x = F.relu(self.fc2(x))  \n",
    "        # Aplica la última capa completamente conectada (sin activación, ya que es la salida final)\n",
    "        x = self.fc3(x)  \n",
    "        return x  # Devuelve la salida final (logits para las 10 clases)\n",
    "    \n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Primera capa convolucional: 3 canales de entrada (RGB), 8 filtros, tamaño de kernel 3x3\n",
    "        self.conv1 = nn.Conv2d(3, 20, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Capa de pooling: tamaño 2x2, stride 2\n",
    "        # Segunda capa convolucional: 8 canales de entrada, 20 filtros, tamaño de kernel 3x3\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        # Ajuste de la capa completamente conectada para las nuevas dimensiones\n",
    "        self.fc1 = nn.Linear(50 * 5 * 5, 500)  # 20 filtros, tamaño 5x5 después de convoluciones y pooling\n",
    "        self.fc3 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # Primera capa convolucional + ReLU + pooling\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Segunda capa convolucional + ReLU + pooling\n",
    "        x = torch.flatten(x, 1)  # Aplanar todas las dimensiones excepto el batch\n",
    "        x = F.relu(self.fc1(x))  # Primera capa completamente conectada + ReLU\n",
    "        x = self.fc3(x)  # Capa de salida\n",
    "        return x\n",
    "    \n",
    "  \n",
    "net1 = Net1()\n",
    "net2 = Net2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.925\n",
      "[1,  4000] loss: 0.180\n",
      "[1,  6000] loss: 0.130\n",
      "[1,  8000] loss: 0.097\n",
      "[1, 10000] loss: 0.087\n",
      "[1, 12000] loss: 0.089\n",
      "[1, 14000] loss: 0.079\n",
      "[2,  2000] loss: 0.061\n",
      "[2,  4000] loss: 0.066\n",
      "[2,  6000] loss: 0.059\n",
      "[2,  8000] loss: 0.057\n",
      "[2, 10000] loss: 0.053\n",
      "[2, 12000] loss: 0.057\n",
      "[2, 14000] loss: 0.056\n",
      "[1,  2000] loss: 0.274\n",
      "[1,  4000] loss: 0.077\n",
      "[1,  6000] loss: 0.063\n",
      "[2,  2000] loss: 0.033\n",
      "[2,  4000] loss: 0.039\n",
      "[2,  6000] loss: 0.039\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Redimensiona las imágenes a 32x32\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convierte imágenes de 1 canal a 3 canales\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalización para 3 canales\n",
    "])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.SGD(net1.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Entrenamiento para net1\n",
    "for epoch in range(2):  # usamos un bucle para reproducir las epoch a través del set de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is una lista de [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer1.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net1(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print cada 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "\n",
    "#Cargamos el dataset para el net2\n",
    "batch_size_net2 = 8  # Cambiar el batch size para Net2\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_net2,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_net2,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer2 = optim.SGD(net2.parameters(), lr=0.003, momentum=0.9)\n",
    "\n",
    "# Entrenamiento para net2\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy de net1 en el conjunto de prueba: 98.66%\n",
      "Accuracy de net2 en el conjunto de prueba: 99.13%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "def evaluate_model(model, testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Desactiva el cálculo del gradiente para la evaluación\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Obtén la clase con la mayor probabilidad\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Calcular el accuracy para net1\n",
    "accuracy_net1 = evaluate_model(net1, testloader)\n",
    "print(f'Accuracy de net1 en el conjunto de prueba: {accuracy_net1:.2f}%')\n",
    "\n",
    "# Calcular el accuracy para net2\n",
    "accuracy_net2 = evaluate_model(net2, testloader)\n",
    "print(f'Accuracy de net2 en el conjunto de prueba: {accuracy_net2:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Diferente número de neuronas en las capas conectadas***\n",
    "Aunque la net2 tiene una capa menos completamente conectada, las dos capas de la net2 contienen más neuronas por lo que puede aprender relaciones más complejas \n",
    "\n",
    "***Diferente Batch size***\n",
    "Al cambiar el batch size cada epoch procesa un número diferente de imagenes, al cambiar el número de batch_size los pesos son más estables.\n",
    "\n",
    "Por otra parte y como apunte final se puede mejorar el desempeño de la Net2 aún más aumentando el número de capas convolucionales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
